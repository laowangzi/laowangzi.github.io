---
published: true
title: 降维算法学习之MDDM
category: algorithm
tags: 
  - python
  - algorithm
layout: post

---
#降维算法学习之MDDM
项目中涉及到MDDM（Multi-label dimensionality reduction via dependency maximization）降维算法，借此机会研究学习。

该算法如其名称所述，是适用于 多标签学习（多标签特征工程）的情况。利用希尔伯特施密特函数挖掘数据特征与标签之间的关系，以此进行降维。属于特征提取的范畴。

针对本算法，初学时首先想到了几个问题待慢慢学习探究：
1.什么是希尔伯特施密特函数？为什么此函数可以表征标签与数据的关系？2.具体如何对特征进行映射？3.该算法的适用性和局限性如何？
#数学基础
**希尔伯特空间**：希尔伯特空间是欧几里德空间的一个推广，其不再局限于有限维的情形。与欧几里德空间相仿，希尔伯特空间也是一个内积空间，其上有距离和角的概念（及由此引申而来的正交性与垂直性的概念）

**HSIC（Hilbert-Schmidt independence criterion）**：算法的主要理论依据是利用希尔伯特施密特独立性检验来评估特征与标签的独立性HSIC(F,Y,Pxy) = (N −1)−2tr(HKHL)
#MDDM算法
MDDM算法来自于周志华和张Yin在2009年的一篇文章Multi-Label Dimensionality Reduction via Dependence Maximization

算法提出的动机：考虑到特征描述与同一对象相关的标签之间应该存在某种关系，我们试图寻找一个输入和输出之间的依赖性最大化的低维特征空间

##1.Uncorrelated Projection Dimensionality Reduction 不相关投影降维

###1.1线性情况
Thus, the optimization problem reduces to deriving eigenvalues of a D×D matrix and the computational complexity is O(dD2)for obtaining the largest d eigenvalues
（因此，优化问题归结为求D×D矩阵的特征值，求取最大D特征值的计算复杂度为O（dD2））

####1.2非线性情况

##2Uncorrelated Subspace Dimensionality Reduction 不相关子空间降维

经过投影后的低维特征仍然会存在一些冗余的情况，现在的目标是消除特征间的依赖关系。
###2.1线性情况
###2.2非线性情况